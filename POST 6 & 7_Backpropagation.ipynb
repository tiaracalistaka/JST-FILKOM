{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvonXDMsQP1k"
      },
      "source": [
        "# Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "YzH-ilE2twTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada post-test kali ini akan membandingkan dua jenis fungsi aktivasi yang biasa digunakan dalam backpropogation"
      ],
      "metadata": {
        "id": "-gGbt71BdLJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi Aktivasi Sigmoid dengan turunannya\n",
        "def sig(X):\n",
        "    X = np.clip(X, -500, 500)  # Prevent overflow in exponential calculation\n",
        "    return [1 / (1 + np.exp(-x)) for x in X]\n",
        "\n",
        "def sigd(X):\n",
        "  output = []\n",
        "  for i, x in enumerate(X):\n",
        "    s = sig([x])[0]\n",
        "    output.append(s * (1 - s))\n",
        "  return output\n",
        "\n",
        "#Fungsi Aktivasi Hyperbolic Tangent dengan turunannya\n",
        "def tanh(X):\n",
        "    return [np.tanh(x) for x in X]\n",
        "\n",
        "def tanhd(X):\n",
        "    output = []\n",
        "    for x in X:\n",
        "        t = np.tanh(x)\n",
        "        output.append(1 - t ** 2)\n",
        "    return output"
      ],
      "metadata": {
        "id": "BTLa3NWvz7sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_enc(lbl, min_val=0):\n",
        "  mi = min(lbl)\n",
        "  enc = np.full((len(lbl), max(lbl) - mi + 1), min_val, np.int8)\n",
        "\n",
        "  for i, x in enumerate(lbl):\n",
        "    enc[i, x - mi] = 1\n",
        "\n",
        "  return enc\n",
        "\n",
        "def onehot_dec(enc, mi=0):\n",
        "  return [np.argmax(e) + mi for e in enc]"
      ],
      "metadata": {
        "id": "MopOydIkUjtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hihqFCY_ctZ3"
      },
      "source": [
        "### a) Fungsi *Training* Backpropagation\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTlk5igwcvc5"
      },
      "source": [
        "import time\n",
        "def bp_fit_sig(X, target, layer_conf, max_epoch, max_error=.1, learn_rate=.1, print_per_epoch=100):\n",
        "  start_time = time.time()\n",
        "  np.random.seed(1)\n",
        "  # Lengkapi kode Dibawah ini\n",
        "  nin = [np.empty(i) for i in layer_conf]\n",
        "  n = [np.empty(j + 1) if i < len(layer_conf) - 1 else np.empty(j) for i, j in enumerate(layer_conf)]\n",
        "\n",
        "  w = [np.random.rand(layer_conf[i] + 1, layer_conf[i + 1]) for i in range(len(layer_conf) - 1)]\n",
        "\n",
        "  dw = [np.empty((layer_conf[i] + 1, layer_conf[i + 1])) for i in range(len(layer_conf) - 1)]\n",
        "  d = [np.empty(s) for s in layer_conf[1:]]\n",
        "  din = [np.empty(s) for s in layer_conf[1:-1]]\n",
        "  epoch = 0\n",
        "  mse = 1\n",
        "  for i in range(0, len(n)-1):\n",
        "    n[i][-1] = 1\n",
        "  while (max_epoch == -1 or epoch < max_epoch) and mse > max_error:\n",
        "    epoch += 1\n",
        "    mse = 0\n",
        "    for r in range(len(X)):\n",
        "      n[0][:-1] = X[r]\n",
        "      for L in range(1, len(layer_conf)):\n",
        "        nin[L] = np.dot(n[L-1], w[L-1])\n",
        "        n[L][:len(nin[L])] = sig(nin[L])\n",
        "      e = target[r] - n[-1]\n",
        "      mse += sum(e ** 2)\n",
        "      d[-1] = e * sigd(nin[-1])\n",
        "      dw[-1] = learn_rate * d[-1] * n[-2].reshape((-1, 1))\n",
        "      for L in range(len(layer_conf) - 1, 1, -1):\n",
        "\n",
        "        # Lengkapi kode Dibawah ini\n",
        "        din[L-2] = np.dot(d[L-1],np.transpose(w[L-1][:-1]))\n",
        "        d[L-2] = din[L-2] * np.array(sigd(nin[L-1]))\n",
        "        dw[L-2] = (learn_rate * d[L-2]) *n[L-2].reshape((-1, 1))\n",
        "\n",
        "      w += dw\n",
        "    mse /= len(X)\n",
        "    if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
        "      print(f'Epoch {epoch}, MSE: {mse}')\n",
        "  execution = time.time() - start_time\n",
        "  print(\"Waktu eksekusi: %s detik\" % execution)\n",
        "  return w, epoch, mse"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Membuat fungsi training backpropagation dengan menggunakan fungsi aktivasi tanh\n",
        "import time\n",
        "def bp_fit_tanh(X, target, layer_conf, max_epoch, max_error=.1, learn_rate=.1, print_per_epoch=100):\n",
        "  start_time = time.time()\n",
        "  np.random.seed(1)\n",
        "  # Lengkapi kode Dibawah ini\n",
        "  nin = [np.empty(i) for i in layer_conf]\n",
        "  n = [np.empty(j + 1) if i < len(layer_conf) - 1 else np.empty(j) for i, j in enumerate(layer_conf)]\n",
        "\n",
        "  w = [np.random.rand(layer_conf[i] + 1, layer_conf[i + 1]) for i in range(len(layer_conf) - 1)]\n",
        "  dw = [np.empty((layer_conf[i] + 1, layer_conf[i + 1])) for i in range(len(layer_conf) - 1)]\n",
        "  d = [np.empty(s) for s in layer_conf[1:]]\n",
        "  din = [np.empty(s) for s in layer_conf[1:-1]]\n",
        "  epoch = 0\n",
        "  mse = 1\n",
        "  for i in range(0, len(n)-1):\n",
        "    n[i][-1] = 1\n",
        "  while (max_epoch == -1 or epoch < max_epoch) and mse > max_error:\n",
        "    epoch += 1\n",
        "    mse = 0\n",
        "    for r in range(len(X)):\n",
        "      n[0][:-1] = X[r]\n",
        "      for L in range(1, len(layer_conf)):\n",
        "        nin[L] = np.dot(n[L-1], w[L-1])\n",
        "        n[L][:len(nin[L])] = tanh(nin[L])\n",
        "      e = target[r] - n[-1]\n",
        "      mse += sum(e ** 2)\n",
        "      d[-1] = e * tanhd(nin[-1])\n",
        "      dw[-1] = learn_rate * d[-1] * n[-2].reshape((-1, 1))\n",
        "      for L in range(len(layer_conf) - 1, 1, -1):\n",
        "\n",
        "        # Lengkapi kode Dibawah ini\n",
        "        din[L-2] = np.dot(d[L-1],np.transpose(w[L-1][:-1]))\n",
        "        d[L-2] = din[L-2] * np.array(tanhd(nin[L-1]))\n",
        "        dw[L-2] = (learn_rate * d[L-2]) *n[L-2].reshape((-1, 1))\n",
        "\n",
        "      w += dw\n",
        "    mse /= len(X)\n",
        "    if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
        "      print(f'Epoch {epoch}, MSE: {mse}')\n",
        "  execution = time.time() - start_time\n",
        "  print(\"Waktu eksekusi: %s detik\" % execution)\n",
        "  return w, epoch, mse"
      ],
      "metadata": {
        "id": "Pet6ptVOTxUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJA_9btdc3ED"
      },
      "source": [
        "### b) Fungsi *Testing* Backpropagation\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zyXIu_ec9go"
      },
      "source": [
        "def bp_predict_sig(X, w):\n",
        "  n = [np.empty(len(i)) for i in w]\n",
        "  nin = [np.empty(len(i[0])) for i in w]\n",
        "  predict = []\n",
        "  n.append(np.empty(len(w[-1][0])))\n",
        "  for x in X:\n",
        "    n[0][:-1] = x\n",
        "    for L in range(0, len(w)):\n",
        "      nin[L] = np.dot(n[L], w[L])\n",
        "      n[L + 1][:len(nin[L])] = sig(nin[L])\n",
        "    predict.append(n[-1].copy())\n",
        "  return predict"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Membuat fungsi testing backpropagation dengan menggunakan fungsi aktivasi tanh\n",
        "def bp_predict_tanh(X, w):\n",
        "    n = [np.empty(len(i)) for i in w]\n",
        "    nin = [np.empty(len(i[0])) for i in w]\n",
        "    predict = []\n",
        "    n.append(np.empty(len(w[-1][0])))\n",
        "\n",
        "    for x in X:\n",
        "        n[0][:-1] = x\n",
        "        for L in range(0, len(w)):\n",
        "            nin[L] = np.dot(n[L], w[L])\n",
        "            n[L + 1][:len(nin[L])] = tanh(nin[L])\n",
        "        predict.append(n[-1].copy())\n",
        "\n",
        "    return predict"
      ],
      "metadata": {
        "id": "paHySilia3gw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZxy_M5Jc-ko"
      },
      "source": [
        "### c) Klasifikasi dataset wine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan pelatihan pada dataset wine dengan menggunakan 2 fungsi pelatihan yang telah dibuat!\n",
        "\n",
        "Konfigurasi kedua pelatihan harus sama (epoch, hidden layer, learning rate, dll).\n",
        "Akurasi yang diharapkan di setiap pelatihan adalah > 0.98"
      ],
      "metadata": {
        "id": "4xj7DqCdudcF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw1L_Q3JdHk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4322a34d-5527-4adc-84a0-582b7f9da620"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "wine = datasets.load_wine()\n",
        "X = minmax_scale(wine.data)\n",
        "Y = onehot_enc(wine.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=.3,random_state=1)\n",
        "#Isi jumlah layer yang digunakan dengan jumlah hidden layer #\n",
        "w, ep, mse = bp_fit_sig(X_train, y_train, layer_conf=(13, 10, 3),learn_rate=0.1, max_epoch=10, max_error=0.1, print_per_epoch=25)\n",
        "\n",
        "print(f'Epochs: {ep}, MSE: {mse}')\n",
        "\n",
        "predict = bp_predict_sig(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict, y_test)\n",
        "\n",
        "print('Output:', predict)\n",
        "print('True :', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waktu eksekusi: 0.30729198455810547 detik\n",
            "Epochs: 10, MSE: 1.954027674036451\n",
            "Output: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "True : [2, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0]\n",
            "Accuracy: 0.42592592592592593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "wine = datasets.load_wine()\n",
        "X = minmax_scale(wine.data)\n",
        "Y = onehot_enc(wine.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
        "test_size=.3,random_state=1)\n",
        "#Isi jumlah layer yang digunakan dengan jumlah hidden layer #\n",
        "w, ep, mse = bp_fit_tanh(X_train, y_train, layer_conf=(13, 3, 3),learn_rate=0.1, max_epoch=10, max_error=0.01, print_per_epoch=25)\n",
        "\n",
        "print(f'Epochs: {ep}, MSE: {mse}')\n",
        "\n",
        "predict = bp_predict_tanh(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict, y_test)\n",
        "\n",
        "print('Output:', predict)\n",
        "print('True :', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "mF18HdQgbCXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc33e38f-90a4-4417-ceae-5b85d5abc9b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waktu eksekusi: 0.3185310363769531 detik\n",
            "Epochs: 10, MSE: 1.4600188247380315\n",
            "Output: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "True : [2, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0]\n",
            "Accuracy: 0.42592592592592593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pertanyaan"
      ],
      "metadata": {
        "id": "Lp6y7VWfjVEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Apa perbedaan dari penggunaan fungsi aktivasi sigmoid dengan fungsi aktivasi hyperbolic tangent?\n",
        "2. Coba jelaskan alasan dari perbedaan tersebut sebisa kalian"
      ],
      "metadata": {
        "id": "mP9dzq-kin0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jawaban"
      ],
      "metadata": {
        "id": "RHEJApRcjXu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Fungsi aktivasi sigmoid mengubah setiap nilai input menjadi angka antara 0 dan 1, mirip seperti grafik berbentuk \"S\". Ketika nilai input semakin besar, hasilnya mendekati 1, dan ketika input semakin kecil, hasilnya mendekati 0. Sigmoid sering dipakai karena cocok untuk memodelkan probabilitas atau hasil biner. Namun, kelemahan utamanya adalah terjadinya \"vanishing gradient\" atau peluruhan nilai turunan pada nilai input yang terlalu besar atau terlalu kecil, membuat proses pembelajaran jadi lambat pada lapisan-lapisan yang lebih dalam dalam jaringan saraf. Ini bisa menyebabkan model butuh waktu lama untuk memahami pola, terutama dalam jaringan saraf yang dalam.\n",
        "\n",
        "\n",
        "\n",
        "2. Fungsi aktivasi tanh mirip dengan sigmoid dalam hal bentuk, tapi memberikan hasil antara -1 dan 1. Ini berarti tanh memiliki nilai negatif untuk input negatif dan nilai positif untuk input positif, yang bisa membantu jaringan saraf belajar lebih cepat. Karena rentangnya yang lebih luas dibandingkan sigmoid, fungsi tanh mengurangi masalah vanishing gradient lebih baik, karena outputnya lebih \"sentral\" di sekitar 0. Jadi, informasi bisa mengalir lebih mudah ke lapisan berikutnya, memungkinkan pembelajaran lebih cepat, khususnya dalam jaringan saraf yang dalam.  "
      ],
      "metadata": {
        "id": "4S55HVfLjaZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XiPhiSPBZFZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}